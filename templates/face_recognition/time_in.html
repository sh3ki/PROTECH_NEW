{% load static %}
<!DOCTYPE html>
<html lang="en" class="dark">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>PROTECH - Face Recognition Time In</title>
    <!-- TailwindCSS via CDN -->
    <script src="https://cdn.tailwindcss.com"></script>
    <script>
        tailwind.config = {
            darkMode: 'class',
            theme: {
                extend: {
                    colors: {
                        primary: '#023c82',      /* Dark blue */
                        secondary: '#4c9cfc',    /* Medium blue */
                        tertiary: '#7cb4fc',     /* Light blue */
                        accent: '#7c848c',       /* Medium gray */
                        light: '#c4cfdb',        /* Light gray/blue */
                        dark: '#3c444c',         /* Dark gray */
                    },
                    animation: {
                        'fade-in': 'fadeIn 0.5s ease-in-out',
                        'slide-in': 'slideIn 0.5s ease-out',
                        'pulse-slow': 'pulse 3s cubic-bezier(0.4, 0, 0.6, 1) infinite',
                    },
                    keyframes: {
                        fadeIn: {
                            '0%': { opacity: '0' },
                            '100%': { opacity: '1' },
                        },
                        slideIn: {
                            '0%': { transform: 'translateY(20px)', opacity: '0' },
                            '100%': { transform: 'translateY(0)', opacity: '1' },
                        }
                    }
                }
            }
        }
    </script>
    <style type="text/tailwindcss">
        @layer components {
            .school-btn {
                @apply text-white bg-primary hover:bg-secondary py-3 px-8 rounded-lg font-semibold transition-all duration-300 shadow-md hover:shadow-lg text-center;
            }
            .back-btn {
                @apply flex items-center justify-center gap-2 px-6 py-2 bg-secondary text-white hover:bg-tertiary rounded-full transition-all duration-300 transform hover:-translate-y-1 hover:shadow-lg font-medium;
            }
            .toggle-checkbox:checked {
                @apply right-0 border-secondary;
                background-color: #4c9cfc;
            }
            .toggle-checkbox:checked + .toggle-label {
                @apply bg-tertiary;
            }
            /* New component styles */
            .webcam-container {
                @apply bg-gradient-to-br from-gray-800 to-gray-900 dark:from-gray-900 dark:to-black rounded-xl shadow-xl border border-gray-700 dark:border-gray-800 flex flex-col overflow-hidden;
            }
            .info-card {
                @apply bg-gray-100 dark:bg-gray-700 p-4 rounded-lg border border-gray-200 dark:border-gray-600 transition-all duration-300 hover:shadow-md;
            }
            .dropdown {
                @apply bg-white dark:bg-gray-700 text-gray-800 dark:text-white rounded-lg border-2 border-gray-300 dark:border-gray-600 shadow-sm focus:ring-2 focus:ring-secondary focus:border-secondary;
            }
            .status-badge {
                @apply inline-flex items-center px-2.5 py-0.5 rounded-full text-xs font-medium;
            }
        }
        
        /* Dark mode styles */
        html.dark {
            @apply bg-dark text-light;
        }

        /* Webcam placeholder animation */
        .pulse-ring {
            animation: pulse-ring 1.5s cubic-bezier(0.215, 0.61, 0.355, 1) infinite;
        }
        @keyframes pulse-ring {
            0% {
                transform: scale(0.95);
                opacity: 0.5;
            }
            50% {
                transform: scale(1);
                opacity: 0.75;
            }
            100% {
                transform: scale(0.95);
                opacity: 0.5;
            }
        }

        /* Scrollbar styling */
        .custom-scrollbar::-webkit-scrollbar {
            width: 6px;
        }
        .custom-scrollbar::-webkit-scrollbar-track {
            @apply bg-gray-100 dark:bg-gray-800 rounded-full;
        }
        .custom-scrollbar::-webkit-scrollbar-thumb {
            @apply bg-gray-400 dark:bg-gray-600 rounded-full hover:bg-secondary dark:hover:bg-secondary transition-colors duration-200;
        }
    </style>
</head>
<body class="bg-light dark:bg-dark text-dark dark:text-light min-h-screen flex flex-col transition-colors duration-300">
    <!-- Background image with overlay -->
    <div class="fixed inset-0 z-[-1] bg-white/40 dark:bg-gray-800/30">
        <img src="{% static 'public/images/schoold.svg' %}" alt="Background"
             class="w-full h-full object-cover mix-blend-overlay select-none pointer-events-none opacity-40 dark:opacity-20" />
    </div>

    <!-- Header -->
    <header class="bg-primary/95 backdrop-blur-sm shadow-lg mb-4">
        <div class="py-3 flex justify-between items-center px-6">
            <div class="flex items-center space-x-2">
                <a href="{% url 'landing_page' %}" class="flex items-center gap-2 font-bold text-white text-2xl">
                    <img src="{% static 'public/images/protechlogo.svg' %}" alt="PROTECH Logo" class="h-10 w-10 hover:scale-105 transition-transform" />
                    <span class="inline-block font-extrabold italic tracking-tight leading-tight text-xs ml-1" style="font-family: 'Arial Black', Arial, sans-serif;">
                      THE TECH<br>TO PROTECT
                    </span>
                </a>
            </div>
            <div class="transform hover:scale-[1.01] transition-transform">
                <span class="inline-block font-bold tracking-tight leading-tight text-2xl text-white ml-1" style="font-family: 'Arial Black', Arial, sans-serif;">
                    <span class="text-tertiary">PROTECH</span>: TIME IN
                </span>
            </div>
            <div class="flex items-center gap-4">
                <!-- Dark mode toggle -->
                <div class="flex items-center ml-3">
                    <div class="relative inline-block w-12 mr-2 align-middle select-none">
                        <input type="checkbox" id="toggle-dark" class="toggle-checkbox absolute block w-6 h-6 rounded-full bg-white border-4 appearance-none cursor-pointer"/>
                        <label for="toggle-dark" class="toggle-label block overflow-hidden h-6 rounded-full bg-accent cursor-pointer"></label>
                    </div>
                    <span class="text-white hidden md:inline-block">
                        <svg id="sun-icon" xmlns="http://www.w3.org/2000/svg" class="h-5 w-5" viewBox="0 0 20 20" fill="currentColor">
                            <path fill-rule="evenodd" d="M10 2a1 1 0 011 1v1a1 1 0 11-2 0V3a1 1 0 011-1zm4 8a4 4 0 11-8 0 4 4 0 018 0zm-.464 4.95l.707.707a1 1 0 001.414-1.414l-.707-.707a1 1 0 00-1.414 1.414zm2.12-10.607a1 1 0 010 1.414l-.706.707a1 1 0 11-1.414-1.414l.707-.707a1 1 0 011.414 0zM17 11a1 1 0 100-2h-1a1 1 0 100 2h1zm-7 4a1 1 0 011 1v1a1 1 0 11-2 0v-1a1 1 0 011-1zM5.05 6.464A1 1 0 106.465 5.05l-.708-.707a1 1 0 00-1.414 1.414l.707.707zm1.414 8.486l-.707.707a1 1 0 01-1.414-1.414l.707-.707a1 1 0 011.414 1.414zM4 11a1 1 0 100-2H3a1 1 0 000 2h1z" clip-rule="evenodd" />
                        </svg>
                        <svg id="moon-icon" xmlns="http://www.w3.org/2000/svg" class="h-5 w-5 hidden" viewBox="0 0 20 20" fill="currentColor">
                            <path d="M17.293 13.293A8 8 0 016.707 2.707a8.001 8.001 0 1010.586 10.586z" />
                        </svg>
                    </span>
                </div>
            </div>
        </div>
    </header>
    
    <!-- Main content with full width -->
    <main class="flex-grow animate-fade-in px-6 pb-6">
        <!-- Main container with side-by-side layout -->
        <div class="flex gap-6 h-[calc(100vh-150px)]">
            <!-- Webcam feed container: 2/3 width -->
            <div class="w-2/3 webcam-container">
                <!-- Status indicator bar -->
                <div class="bg-gradient-to-r from-primary to-secondary px-4 py-2 flex justify-between items-center">
                    <div class="flex items-center">
                        <div id="camera-status" class="flex items-center">
                            <span class="relative flex h-3 w-3 mr-2">
                                <span id="status-indicator" class="animate-ping absolute inline-flex h-full w-full rounded-full bg-red-400 opacity-75"></span>
                                <span id="status-dot" class="relative inline-flex rounded-full h-3 w-3 bg-red-500"></span>
                            </span>
                            <span id="status-text" class="text-white font-medium">Inactive</span>
                        </div>
                    </div>
                    
                    <!-- Camera selection dropdown with improved design -->
                    <div class="flex items-center space-x-3">
                        <label for="camera-select" class="text-white font-medium">Camera:</label>
                        <select id="camera-select" class="dropdown py-1 px-3 text-sm">
                            <option value="">Select a camera</option>
                        </select>
                    </div>
                </div>
                
                <!-- Webcam placeholder/feed container -->
                <div class="flex-1 flex items-center justify-center relative bg-black/40">
                    <!-- Camera placeholder (shown when no camera) -->
                    <div id="camera-placeholder" class="absolute inset-0 flex flex-col items-center justify-center text-white">
                        <div class="w-24 h-24 rounded-full bg-gray-700/50 pulse-ring flex items-center justify-center mb-4">
                            <svg xmlns="http://www.w3.org/2000/svg" class="h-12 w-12" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                                <path stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="M15 10l4.553-2.276A1 1 0 0121 8.618v6.764a1 1 0 01-1.447.894L15 14M5 18h8a2 2 0 002-2V8a2 2 0 00-2-2H5a2 2 0 00-2 2v8a2 2 0 002 2z" />
                            </svg>
                        </div>
                        <p class="text-xl font-medium text-center">No Camera Selected</p>
                        <p class="text-sm text-gray-400 mt-1 mb-4">Please select a camera from the dropdown above</p>
                    </div>
                    
                    <!-- Actual video element (hidden, used for processing) -->
                    <video id="webcam" autoplay playsinline muted class="w-full h-full object-cover" style="position: relative; z-index: 1;"></video>
                    
                    <!-- Canvas overlay for bounding boxes -->
                    <canvas id="overlay-canvas" class="absolute top-0 left-0 w-full h-full pointer-events-none" style="position: absolute !important; z-index: 9999 !important; top: 0 !important; left: 0 !important; width: 100% !important; height: 100% !important;"></canvas>
                    
                    <!-- FPS Counter -->
                    <div class="absolute top-4 right-4 bg-black/70 text-white px-3 py-2 rounded-lg">
                        <span id="fps-counter" class="text-green-500 font-bold">0 FPS</span>
                    </div>
                </div>
            </div>
            
            <!-- Student info container: 1/3 width -->
            <div class="w-1/3 flex flex-col rounded-xl shadow-xl overflow-hidden border border-gray-200 dark:border-gray-700">
                <!-- Header section with count and stats -->
                <div class="bg-white dark:bg-gray-800 p-4 border-b border-gray-200 dark:border-gray-700">
                    <div class="flex justify-between items-center mb-2">
                        <h2 class="text-xl font-bold text-primary dark:text-tertiary">Recognized Students</h2>
                        <div class="bg-primary/10 dark:bg-tertiary/20 rounded-full px-3 py-1 text-sm font-medium text-primary dark:text-tertiary">
                            <span id="student-count">0</span> Present
                        </div>
                    </div>
                    <div class="flex space-x-2 text-sm text-gray-600 dark:text-gray-400">
                        <span>Today: <span id="today-date">{% now "F j, Y" %}</span></span>
                    </div>
                </div>
                
                <!-- Scrollable content area with improved styling -->
                <div class="flex-1 overflow-y-auto custom-scrollbar bg-gray-50 dark:bg-gray-900/60">
                    <div id="student-list" class="p-4 space-y-3">
                        <!-- This will be populated dynamically, but here's sample styling -->
                        <div class="info-card group hover:scale-[1.01] transform transition-all duration-200">
                            <div class="flex justify-between items-start">
                                <div>
                                    <div class="flex items-center">
                                        <h3 class="font-semibold text-gray-800 dark:text-white">John Smith</h3>
                                        <span class="ml-2 status-badge bg-green-100 text-green-800 dark:bg-green-900 dark:text-green-200">
                                            On Time
                                        </span>
                                    </div>
                                    <p class="text-sm text-gray-600 dark:text-gray-300 mt-1">Student ID: 2023-0001</p>
                                </div>
                                <div class="text-right">
                                    <p class="text-xs text-gray-500 dark:text-gray-400">Today</p>
                                    <p class="text-sm font-medium text-gray-700 dark:text-gray-300">10:30 AM</p>
                                </div>
                            </div>
                        </div>
                        
                        <div class="info-card group hover:scale-[1.01] transform transition-all duration-200">
                            <div class="flex justify-between items-start">
                                <div>
                                    <div class="flex items-center">
                                        <h3 class="font-semibold text-gray-800 dark:text-white">Sarah Johnson</h3>
                                        <span class="ml-2 status-badge bg-green-100 text-green-800 dark:bg-green-900 dark:text-green-200">
                                            On Time
                                        </span>
                                    </div>
                                    <p class="text-sm text-gray-600 dark:text-gray-300 mt-1">Student ID: 2023-0002</p>
                                </div>
                                <div class="text-right">
                                    <p class="text-xs text-gray-500 dark:text-gray-400">Today</p>
                                    <p class="text-sm font-medium text-gray-700 dark:text-gray-300">10:35 AM</p>
                                </div>
                            </div>
                        </div>
                        
                        <div class="info-card group hover:scale-[1.01] transform transition-all duration-200">
                            <div class="flex justify-between items-start">
                                <div>
                                    <div class="flex items-center">
                                        <h3 class="font-semibold text-gray-800 dark:text-white">Miguel Santos</h3>
                                        <span class="ml-2 status-badge bg-yellow-100 text-yellow-800 dark:bg-yellow-900 dark:text-yellow-200">
                                            Late
                                        </span>
                                    </div>
                                    <p class="text-sm text-gray-600 dark:text-gray-300 mt-1">Student ID: 2023-0003</p>
                                </div>
                                <div class="text-right">
                                    <p class="text-xs text-gray-500 dark:text-gray-400">Today</p>
                                    <p class="text-sm font-medium text-gray-700 dark:text-gray-300">10:45 AM</p>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </main>
    
    <!-- Camera test modal with improved design -->
    <div id="camera-test-modal" class="fixed inset-0 z-50 hidden">
        <!-- Modal backdrop with blur effect -->
        <div class="absolute inset-0 bg-black/60 backdrop-blur-sm transition-all duration-300"></div>
        
        <!-- Modal content - centered with improved design -->
        <div class="absolute top-1/2 left-1/2 transform -translate-x-1/2 -translate-y-1/2 bg-white dark:bg-gray-800 w-11/12 max-w-2xl rounded-xl shadow-2xl overflow-hidden border border-gray-200 dark:border-gray-700 transition-all duration-300">
            <!-- Modal header with gradient -->
            <div class="bg-gradient-to-r from-primary to-secondary px-5 py-4 flex justify-between items-center">
                <h3 class="text-lg font-semibold text-white flex items-center">
                    <svg xmlns="http://www.w3.org/2000/svg" class="h-5 w-5 mr-2" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 10l4.553-2.276A1 1 0 0121 8.618v6.764a1 1 0 01-1.447.894L15 14M5 18h8a2 2 0 002-2V8a2 2 0 00-2-2H5a2 2 0 00-2 2v8a2 2 0 002 2z" />
                    </svg>
                    Camera Test
                </h3>
                <button id="close-modal" class="text-white hover:bg-white/20 rounded-full p-1 transition-colors">
                    <svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12" />
                    </svg>
                </button>
            </div>
            
            <!-- Modal body with improved design -->
            <div class="p-6 flex flex-col items-center">
                <p class="mb-4 text-gray-700 dark:text-gray-300 text-center">
                    Testing your camera feed. Please make sure the camera is working fine before confirming.
                </p>
                
                <!-- Camera preview with better styling -->
                <div class="bg-black rounded-lg overflow-hidden w-full h-120 mb-4 shadow-inner border border-gray-700">
                    <video id="test-video" autoplay playsinline muted class="w-full h-full object-cover"></video>
                </div>
                
                <!-- Modal footer with improved buttons -->
                <div class="flex justify-center gap-6 mt-6">
                    <button id="cancel-camera" class="px-8 py-2.5 bg-gradient-to-r from-gray-300 to-gray-200 dark:from-gray-700 dark:to-gray-800 text-gray-700 dark:text-gray-100 rounded-lg font-medium transition-all duration-300 transform hover:-translate-y-0.5 hover:shadow-lg border border-gray-300 dark:border-gray-600 focus:outline-none focus:ring-2 focus:ring-gray-400 dark:focus:ring-gray-500 flex items-center gap-2">
                        <svg xmlns="http://www.w3.org/2000/svg" class="h-5 w-5" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12" />
                        </svg>
                        Cancel
                    </button>
                    <button id="confirm-camera" class="px-8 py-2.5 bg-gradient-to-r from-secondary to-tertiary text-white font-medium rounded-lg shadow-md transition-all duration-300 transform hover:-translate-y-0.5 hover:shadow-lg hover:from-secondary/90 hover:to-tertiary/90 focus:outline-none focus:ring-2 focus:ring-tertiary focus:ring-offset-2 dark:focus:ring-offset-gray-800 flex items-center gap-2">
                        <svg xmlns="http://www.w3.org/2000/svg" class="h-5 w-5" viewBox="0 0 20 20" fill="currentColor">
                            <path fill-rule="evenodd" d="M16.707 5.293a1 1 0 010 1.414l-8 8a1 1 0 01-1.414 0l-4-4a1 1 0 011.414-1.414L8 12.586l7.293-7.293a1 1 0 011.414 0z" clip-rule="evenodd" />
                        </svg>
                        Confirm Camera
                    </button>
                </div>
            </div>
        </div>
    </div>
    
    <!-- Footer with improved design -->
    <footer class="bg-primary/95 backdrop-blur-sm text-white py-3 border-t border-primary">
        <div class="text-center">
            <p>&copy; {% now "Y" %} PROTECH. All rights reserved.</p>
        </div>
    </footer>

    <!-- Dark mode toggle script -->
    <script>
        document.addEventListener('DOMContentLoaded', () => {
            const html = document.documentElement;
            const toggleCheckbox = document.getElementById('toggle-dark');
            const sunIcon = document.getElementById('sun-icon');
            const moonIcon = document.getElementById('moon-icon');
            
            // Check for user preference or default to dark
            const isDarkMode = localStorage.getItem('darkMode') !== 'false';
            
            // Apply initial state
            if (isDarkMode) {
                html.classList.add('dark');
                toggleCheckbox.checked = true;
                sunIcon.classList.add('hidden');
                moonIcon.classList.remove('hidden');
            } else {
                html.classList.remove('dark');
                sunIcon.classList.remove('hidden');
                moonIcon.classList.add('hidden');
            }
            
            // Toggle dark mode
            toggleCheckbox.addEventListener('change', () => {
                if (toggleCheckbox.checked) {
                    html.classList.add('dark');
                    localStorage.setItem('darkMode', 'true');
                    sunIcon.classList.add('hidden');
                    moonIcon.classList.remove('hidden');
                } else {
                    html.classList.remove('dark');
                    localStorage.setItem('darkMode', 'false');
                    sunIcon.classList.remove('hidden');
                    moonIcon.classList.add('hidden');
                }
            });
        });
    </script>
    
    <!-- Camera selection and testing script with improved functionality -->
    <script>
        document.addEventListener('DOMContentLoaded', () => {
            const cameraSelect = document.getElementById('camera-select');
            const modal = document.getElementById('camera-test-modal');
            const closeModal = document.getElementById('close-modal');
            const cancelCamera = document.getElementById('cancel-camera');
            const confirmCamera = document.getElementById('confirm-camera');
            const testVideo = document.getElementById('test-video');
            const webcamFeed = document.getElementById('webcam'); // Changed from 'webcam-feed' to 'webcam'
            const cameraPlaceholder = document.getElementById('camera-placeholder');
            const statusIndicator = document.getElementById('status-indicator');
            const statusDot = document.getElementById('status-dot');
            const statusText = document.getElementById('status-text');
            
            let currentStream = null;
            let activeCameraId = null;
            let mainStream = null; // Track main webcam stream separately
            
            // Detect if we're on a mobile device (tablet or phone)
            const isMobileDevice = /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
            
            // Helper function to safely stop any active stream
            function stopMediaStream(stream) {
                if (stream) {
                    stream.getTracks().forEach(track => {
                        track.stop();
                    });
                    return null;
                }
                return null;
            }
            
            // Update camera status
            function updateCameraStatus(active) {
                if (active) {
                    statusIndicator.classList.remove('bg-red-400');
                    statusIndicator.classList.add('bg-green-400');
                    statusDot.classList.remove('bg-red-500');
                    statusDot.classList.add('bg-green-500');
                    statusText.textContent = 'Active';
                } else {
                    statusIndicator.classList.remove('bg-green-400');
                    statusIndicator.classList.add('bg-red-400');
                    statusDot.classList.remove('bg-green-500');
                    statusDot.classList.add('bg-red-500');
                    statusText.textContent = 'Inactive';
                }
            }
            
            // Get available camera devices with improved error handling
            async function getAvailableCameras() {
                try {
                    // Clear previous options
                    cameraSelect.innerHTML = '';
                    
                    // Add a default option
                    const defaultOption = document.createElement('option');
                    defaultOption.value = '';
                    defaultOption.textContent = 'Select a camera';
                    cameraSelect.appendChild(defaultOption);
                    
                    // Request permission first
                    await navigator.mediaDevices.getUserMedia({ video: true })
                        .then(stream => {
                            // Stop this initial stream right away
                            stream.getTracks().forEach(track => track.stop());
                            
                            // Now list the devices
                            return navigator.mediaDevices.enumerateDevices();
                        })
                        .then(devices => {
                            const videoDevices = devices.filter(device => device.kind === 'videoinput');
                            
                            // Add camera options
                            videoDevices.forEach((device, index) => {
                                const option = document.createElement('option');
                                option.value = device.deviceId;
                                
                                // Try to identify front/back cameras on mobile devices
                                let label = device.label || `Camera ${index + 1}`;
                                
                                if (isMobileDevice) {
                                    // Many devices identify camera positions in their labels
                                    if (device.label) {
                                        if (/front/i.test(device.label)) {
                                            label = `Front Camera (${label})`;
                                        } else if (/back/i.test(device.label)) {
                                            label = `Back Camera (${label})`;
                                        }
                                    }
                                    
                                    // If no identification in label, make a best guess
                                    if (videoDevices.length === 2) {
                                        // Many mobile devices have exactly 2 cameras
                                        if (index === 0) {
                                            label = label.includes('Front') ? label : `Front Camera`;
                                        } else {
                                            label = label.includes('Back') ? label : `Back Camera`;
                                        }
                                    }
                                }
                                
                                option.textContent = label;
                                cameraSelect.appendChild(option);
                            });
                            
                            if (videoDevices.length === 0) {
                                const option = document.createElement('option');
                                option.textContent = 'No cameras found';
                                option.disabled = true;
                                cameraSelect.appendChild(option);
                            } else if (videoDevices.length === 1) {
                                // If only one camera, select it automatically
                                cameraSelect.value = videoDevices[0].deviceId;
                                startCameraTest(videoDevices[0].deviceId);
                            }
                        });
                } catch (error) {
                    console.error('Error accessing media devices:', error);
                    const errorOption = document.createElement('option');
                    
                    if (error.name === 'NotAllowedError' || error.name === 'PermissionDeniedError') {
                        errorOption.textContent = 'Camera permission denied';
                    } else if (error.name === 'NotFoundError') {
                        errorOption.textContent = 'No cameras available';
                    } else {
                        errorOption.textContent = 'Error accessing cameras';
                    }
                    
                    errorOption.disabled = true;
                    cameraSelect.innerHTML = '';
                    cameraSelect.appendChild(errorOption);
                    
                    // Show appropriate error message
                    let errorMsg = 'Unable to access cameras.';
                    if (isMobileDevice) {
                        errorMsg += ' Please ensure you have granted camera permissions in your browser settings and try again.';
                    } else {
                        errorMsg += ' Please ensure your camera is connected and you have granted permission.';
                    }
                    alert(errorMsg);
                }
            }
            
            // Function to create appropriate constraints based on device and camera
            function createVideoConstraints(deviceId) {
                // Create optimal constraints for the current device
                const constraints = {
                    video: {
                        deviceId: deviceId ? { exact: deviceId } : undefined,
                    }
                };
                
                // Add device-specific settings
                if (isMobileDevice) {
                    // Mobile devices often work better with these constraints
                    constraints.video.width = { ideal: 720 };
                    constraints.video.height = { ideal: 1280 };
                    
                    // Some mobile browsers work better with these settings
                    constraints.video.facingMode = { ideal: "user" };
                } else {
                    // Desktop settings
                    constraints.video.width = { ideal: 1280 };
                    constraints.video.height = { ideal: 720 };
                }
                
                return constraints;
            }
            
            // Start camera for testing with improved error handling and mobile support
            async function startCameraTest(deviceId) {
                try {
                    // Stop any existing test stream
                    currentStream = stopMediaStream(currentStream);
                    
                    // Create appropriate constraints
                    const constraints = createVideoConstraints(deviceId);
                    
                    currentStream = await navigator.mediaDevices.getUserMedia(constraints);
                    testVideo.srcObject = currentStream;
                    
                    // Show the modal
                    modal.classList.remove('hidden');
                    
                    // Handle orientation change for mobile devices
                    if (isMobileDevice) {
                        window.addEventListener('orientationchange', () => {
                            // Short timeout to let the orientation change complete
                            setTimeout(() => {
                                // Refresh the video if orientation changes
                                if (testVideo.srcObject) {
                                    const track = testVideo.srcObject.getVideoTracks()[0];
                                    if (track) {
                                        track.applyConstraints({
                                            width: { ideal: window.innerWidth },
                                            height: { ideal: window.innerHeight }
                                        }).catch(err => console.error('Failed to update constraints:', err));
                                    }
                                }
                            }, 300);
                        }, { once: false });
                    }
                } catch (error) {
                    console.error('Error starting camera test:', error);
                    
                    // Handle specific error types with better messages
                    let errorMsg = 'Failed to access the camera.';
                    
                    if (error.name === 'NotAllowedError' || error.name === 'PermissionDeniedError') {
                        errorMsg += ' Please check camera permissions and try again.';
                    } else if (error.name === 'NotReadableError' || error.name === 'TrackStartError') {
                        errorMsg += ' The camera may be in use by another application.';
                    } else if (error.name === 'OverconstrainedError') {
                        errorMsg += ' The selected camera cannot satisfy required constraints.';
                    } else {
                        errorMsg += ' Please try selecting a different camera.';
                    }
                    
                    alert(errorMsg);
                    cameraSelect.value = '';
                }
            }
            
            // Start the main webcam feed with improved error handling
            async function startWebcamFeed(deviceId) {
                try {
                    // First, ensure any previous main streams are properly closed
                    if (mainStream) {
                        mainStream = stopMediaStream(mainStream);
                    }
                    
                    // Make sure the video element exists and is ready for a new stream
                    if (!webcamFeed) {
                        console.error('Webcam video element not found!');
                        alert('Error: Video element not found. Please refresh the page.');
                        return;
                    }
                    
                    if (webcamFeed.srcObject) {
                        webcamFeed.srcObject = null;
                    }
                    
                    // Create appropriate constraints
                    const constraints = createVideoConstraints(deviceId);
                    
                    // Remove the timeout - it's causing issues
                    console.log("Starting webcam feed with device ID:", deviceId);
                    console.log("Using constraints:", JSON.stringify(constraints));
                    
                    mainStream = await navigator.mediaDevices.getUserMedia(constraints);
                    console.log("Stream obtained successfully");
                    
                    // Set up the video feed
                    webcamFeed.srcObject = mainStream;
                    // Video is always visible for canvas overlay
                    if (cameraPlaceholder) cameraPlaceholder.classList.add('hidden');
                    
                    // Update UI state
                    activeCameraId = deviceId;
                    updateCameraStatus(true);
                    
                    // Add a play event handler to make sure video actually starts
                    webcamFeed.onplay = () => {
                        console.log('Main webcam feed playing successfully');
                        // Update student count (this would be dynamic in a real app)
                        const studentCountEl = document.getElementById('student-count');
                        if (studentCountEl) studentCountEl.textContent = '3';
                    };
                    
                    // Add error handling for the video element itself
                    webcamFeed.onerror = (event) => {
                        console.error('Video element error:', event);
                        updateCameraStatus(false);
                        resetCameraUI();
                    };
                    
                } catch (error) {
                    console.error('Error starting webcam feed:', error);
                    
                    // Handle specific error cases
                    let errorMsg = 'Failed to start the webcam feed.';
                    
                    if (error.name === 'NotAllowedError') {
                        errorMsg += ' Camera permission was denied.';
                    } else if (error.name === 'NotReadableError' || error.name === 'TrackStartError') {
                        errorMsg += ' The camera is already in use or not readable.';
                    } else if (error.name === 'OverconstrainedError') {
                        errorMsg += ' The selected camera cannot be configured as required.';
                    } else {
                        errorMsg += ' Please try again or select a different camera.';
                    }
                    
                    alert(errorMsg);
                    updateCameraStatus(false);
                    resetCameraUI();
                }
            }
            
            // Reset the camera UI when there's an error
            function resetCameraUI() {
                // Video stays visible for canvas overlay
                if (cameraPlaceholder) cameraPlaceholder.classList.remove('hidden');
                activeCameraId = null;
                updateCameraStatus(false);
            }
            
            // Handle camera selection change
            cameraSelect.addEventListener('change', () => {
                const deviceId = cameraSelect.value;
                if (deviceId) {
                    startCameraTest(deviceId);
                } else {
                    // If "Select a camera" is chosen, stop any streams and show placeholder
                    currentStream = stopMediaStream(currentStream);
                    mainStream = stopMediaStream(mainStream);
                    
                    resetCameraUI();
                    updateCameraStatus(false);
                }
            });
            
            // Close modal and stop test stream
            function closeTestModal() {
                currentStream = stopMediaStream(currentStream);
                modal.classList.add('hidden');
                
                // If no camera was previously confirmed, reset UI
                if (!activeCameraId) {
                    cameraSelect.value = '';
                    updateCameraStatus(false);
                }
            }
            
            closeModal.addEventListener('click', closeTestModal);
            cancelCamera.addEventListener('click', closeTestModal);
            
            // Confirm camera button - with improved timing management
            confirmCamera.addEventListener('click', () => {
                const deviceId = cameraSelect.value;
                
                // Get the test stream's track to potentially reuse
                const testTrack = currentStream ? currentStream.getVideoTracks()[0] : null;
                const cloneTrack = testTrack ? testTrack.clone() : null;
                
                // Stop the test stream
                currentStream = stopMediaStream(currentStream);
                
                // Close the modal
                modal.classList.add('hidden');
                
                // Add a small delay before starting the main feed to allow resources to be released
                setTimeout(() => {
                    // If we have a cloned track, try to use it directly
                    if (cloneTrack && webcamFeed) {
                        try {
                            const newStream = new MediaStream([cloneTrack]);
                            webcamFeed.srcObject = newStream;
                            // Video is always visible for canvas overlay
                            if (cameraPlaceholder) cameraPlaceholder.classList.add('hidden');
                            mainStream = newStream;
                            activeCameraId = deviceId;
                            updateCameraStatus(true);
                            
                            // Update student count (this would be dynamic in a real app)
                            const studentCountEl = document.getElementById('student-count');
                            if (studentCountEl) studentCountEl.textContent = '3';
                            
                            console.log("Successfully reused camera track");
                            return;
                        } catch (e) {
                            console.warn("Failed to reuse track, falling back to new stream:", e);
                        }
                    }
                    
                    // Start the main webcam feed with the selected camera
                    startWebcamFeed(deviceId);
                }, 500); // 500ms delay to allow camera resources to be properly released
            });
            
            // Initialize - get available cameras
            getAvailableCameras();
            
            // Also check for orientation changes in the main feed
            if (isMobileDevice) {
                window.addEventListener('orientationchange', () => {
                    // Apply orientation handling to main camera feed after a short delay
                    if (mainStream) {
                        setTimeout(() => {
                            const track = mainStream.getVideoTracks()[0];
                            if (track) {
                                track.applyConstraints({
                                    width: { ideal: window.innerWidth },
                                    height: { ideal: window.innerHeight }
                            }).catch(err => console.error('Failed to update constraints:', err));
                            }
                        }, 300);
                    }
                });
            }
            
            // Clean up on page unload to ensure camera resources are released
            window.addEventListener('beforeunload', () => {
                stopMediaStream(currentStream);
                stopMediaStream(mainStream);
            });
        });
    </script>
    
    <!-- TensorFlow.js and BlazeFace for face detection -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.11.0/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface@0.0.7/dist/blazeface.js"></script>
    
    <!-- Ultra-Fast Face Recognition System - Integrated -->
    <script>
    (function() {
        const ATTENDANCE_TYPE = 'time_in';
        
        class UltraFastFaceRecognition {
            constructor(attendanceType) {
                this.attendanceType = attendanceType;
                this.video = null;
                this.canvas = null;
                this.ctx = null;
                this.model = null;
                this.isRunning = false;
                this.processingFrame = false;
                this.frameCount = 0;
                this.fps = 0;
                this.lastFpsUpdate = Date.now();
                this.recognitionCooldown = new Map();
                this.cooldownMs = 5000;
            }

            async initialize() {
                console.log('üöÄ Initializing Ultra-Fast Face Recognition...');
                
                this.video = document.getElementById('webcam');
                this.canvas = document.getElementById('overlay-canvas');
                
                if (!this.canvas) {
                    console.error('‚ùå Canvas not found!');
                    return;
                }
                console.log('‚úÖ Canvas element found:', this.canvas);
                
                this.ctx = this.canvas.getContext('2d');
                if (!this.ctx) {
                    console.error('‚ùå Failed to get 2D context!');
                    return;
                }
                console.log('‚úÖ Canvas 2D context created');
                
                // Test drawing
                this.ctx.fillStyle = 'red';
                this.ctx.fillRect(50, 50, 100, 100);
                console.log('üé® Test rectangle drawn (should see red square)');
                setTimeout(() => this.ctx.clearRect(0, 0, this.canvas.width, this.canvas.height), 2000);
                
                console.log('üì• Loading BlazeFace model...');
                this.model = await blazeface.load();
                console.log('‚úÖ BlazeFace model loaded');
            }

            startRecognition() {
                if (!this.model || !this.video) {
                    console.error('Model or video not ready');
                    return;
                }
                
                // CRITICAL FIX: Set canvas size to match VIDEO DISPLAY SIZE (not native resolution)
                const videoRect = this.video.getBoundingClientRect();
                this.canvas.width = videoRect.width;
                this.canvas.height = videoRect.height;
                
                console.log(`üìê Canvas sized to DISPLAY: ${this.canvas.width}x${this.canvas.height}`);
                console.log(`üìê Video native resolution: ${this.video.videoWidth}x${this.video.videoHeight}`);
                console.log(`üìê Video display size: ${videoRect.width}x${videoRect.height}`);
                
                // Calculate scale factors for coordinate transformation
                this.scaleX = videoRect.width / this.video.videoWidth;
                this.scaleY = videoRect.height / this.video.videoHeight;
                console.log(`üìê Scale factors: X=${this.scaleX.toFixed(3)}, Y=${this.scaleY.toFixed(3)}`);
                
                // Draw test rectangles to verify canvas visibility
                this.ctx.fillStyle = 'rgba(255, 255, 0, 0.8)'; // Semi-transparent yellow
                this.ctx.fillRect(10, 10, 100, 100);
                
                this.ctx.strokeStyle = 'red';
                this.ctx.lineWidth = 5;
                this.ctx.strokeRect(0, 0, this.canvas.width, this.canvas.height); // Border around entire canvas
                
                console.log('üü® Test shapes drawn - YOU SHOULD SEE YELLOW SQUARE & RED BORDER NOW!');
                
                this.isRunning = true;
                this.recognitionLoop();
                console.log('‚úÖ Face Recognition STARTED!');
            }

            stopRecognition() {
                this.isRunning = false;
                if (this.ctx) {
                    this.ctx.clearRect(0, 0, this.canvas.width, this.canvas.height);
                }
                console.log('‚èπÔ∏è Face Recognition Stopped');
            }

            async recognitionLoop() {
                if (!this.isRunning) return;
                
                if (!this.processingFrame && this.video.readyState === 4) {
                    this.processingFrame = true;
                    await this.processFrame();
                    this.processingFrame = false;
                }
                
                requestAnimationFrame(() => this.recognitionLoop());
            }

            async processFrame() {
                try {
                    this.ctx.clearRect(0, 0, this.canvas.width, this.canvas.height);
                    
                    const predictions = await this.model.estimateFaces(this.video, false);
                    
                    if (predictions.length === 0) {
                        this.updateFPS();
                        return;
                    }
                    
                    console.log(`üîç Detected ${predictions.length} face(s)`);
                    
                    // Use pre-calculated scale factors (stored in startRecognition)
                    const scaleX = this.scaleX || 1;
                    const scaleY = this.scaleY || 1;
                    
                    const faceEmbeddings = [];
                    const faceBoundingBoxes = [];
                    
                    for (const prediction of predictions) {
                        const start = prediction.topLeft;
                        const end = prediction.bottomRight;
                        const size = [end[0] - start[0], end[1] - start[1]];
                        
                        const faceEmbedding = await this.extractFaceEmbedding(start, size);
                        faceEmbeddings.push(faceEmbedding);
                        
                        // Scale coordinates from video native resolution to canvas display size
                        const scaledBox = {
                            start: [start[0] * scaleX, start[1] * scaleY],
                            end: [end[0] * scaleX, end[1] * scaleY],
                            size: [size[0] * scaleX, size[1] * scaleY]
                        };
                        faceBoundingBoxes.push(scaledBox);
                    }
                    
                    const results = await this.recognizeFaces(faceEmbeddings);
                    console.log('üéØ Recognition results:', results);
                    
                    for (let i = 0; i < results.length; i++) {
                        const result = results[i];
                        const box = faceBoundingBoxes[i];
                        
                        if (result.matched) {
                            console.log(`‚úÖ Matched student: ${result.lrn} ${result.first_name} ${result.last_name} (Confidence: ${(result.confidence * 100).toFixed(1)}%)`);
                            this.drawBoundingBox(box, result, true);
                            this.autoRecordAttendance(result);
                        } else {
                            console.log('‚ùå Unknown face detected');
                            this.drawBoundingBox(box, result, false);
                        }
                    }
                    
                    this.updateFPS();
                    
                } catch (error) {
                    console.error('Error in processFrame:', error);
                }
            }

            async extractFaceEmbedding(start, size) {
                const [x, y] = start;
                const [width, height] = size;
                
                const faceCanvas = document.createElement('canvas');
                faceCanvas.width = 128;
                faceCanvas.height = 128;
                const faceCtx = faceCanvas.getContext('2d');
                
                faceCtx.drawImage(this.video, x, y, width, height, 0, 0, 128, 128);
                
                const imageData = faceCtx.getImageData(0, 0, 128, 128);
                const data = imageData.data;
                
                const embedding = new Array(128);
                for (let i = 0; i < 128; i++) {
                    const idx = i * 4 * 128;
                    embedding[i] = (data[idx] + data[idx + 1] + data[idx + 2]) / (3 * 255);
                }
                
                return embedding;
            }

            async recognizeFaces(faceEmbeddings) {
                try {
                    const response = await fetch('/api/recognize-faces/', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({ face_embeddings: faceEmbeddings })
                    });
                    
                    const data = await response.json();
                    return data.success ? data.results : faceEmbeddings.map(() => ({ matched: false }));
                } catch (error) {
                    console.error('Error in recognizeFaces:', error);
                    return faceEmbeddings.map(() => ({ matched: false }));
                }
            }

            drawBoundingBox(box, result, isMatched) {
                const { start, end } = box;
                const [x1, y1] = start;
                const [x2, y2] = end;
                
                console.log(`üé® Drawing box at [${x1.toFixed(0)},${y1.toFixed(0)}] to [${x2.toFixed(0)},${y2.toFixed(0)}]`);
                console.log(`üé® Canvas size: ${this.canvas.width}x${this.canvas.height}`);
                console.log(`üé® Context exists: ${!!this.ctx}`);
                
                if (!this.ctx) {
                    console.error('‚ùå No canvas context!');
                    return;
                }
                
                const color = isMatched ? '#00FF00' : '#FF0000';
                const bgColor = isMatched ? 'rgba(0, 255, 0, 0.3)' : 'rgba(255, 0, 0, 0.3)';
                
                // Draw thick border
                this.ctx.strokeStyle = color;
                this.ctx.lineWidth = 4;
                console.log(`üé® Drawing rectangle with color ${color}, lineWidth 4`);
                this.ctx.strokeRect(x1, y1, x2 - x1, y2 - y1);
                console.log(`üé® Rectangle drawn!`);
                
                if (isMatched) {
                    // Draw label background (taller for three lines)
                    const labelHeight = 80;
                    const boxWidth = x2 - x1;
                    this.ctx.fillStyle = color;
                    this.ctx.fillRect(x1, y1 - labelHeight, boxWidth, labelHeight);
                    
                    // Draw text in black
                    this.ctx.fillStyle = '#000000';
                    this.ctx.font = 'bold 14px Arial';
                    
                    // Display LRN on first line
                    this.ctx.fillText(`LRN: ${result.lrn || 'N/A'}`, x1 + 8, y1 - 58);
                    // Display full name on second line
                    const fullName = result.name || `${result.first_name || ''} ${result.last_name || ''}`.trim();
                    this.ctx.fillText(fullName, x1 + 8, y1 - 38);
                    // Display confidence on third line
                    const confidence = result.confidence ? `${(result.confidence * 100).toFixed(1)}%` : 'N/A';
                    this.ctx.fillText(`Match: ${confidence}`, x1 + 8, y1 - 18);
                    
                    console.log(`üì¶ Drew green box for ${fullName} (${result.lrn}) at [${x1},${y1}]-[${x2},${y2}]`);
                } else {
                    // Draw label background (single line)
                    const labelHeight = 40;
                    const boxWidth = x2 - x1;
                    this.ctx.fillStyle = color;
                    this.ctx.fillRect(x1, y1 - labelHeight, boxWidth, labelHeight);
                    
                    // Draw text in white for better visibility on red
                    this.ctx.fillStyle = '#FFFFFF';
                    this.ctx.font = 'bold 18px Arial';
                    this.ctx.fillText('UNAUTHORIZED', x1 + 8, y1 - 15);
                    
                    console.log('üì¶ Drew red box for unauthorized face');
                }
            }

            async autoRecordAttendance(result) {
                const studentId = result.student_id;
                const now = Date.now();
                
                if (this.recognitionCooldown.has(studentId)) {
                    const lastRecording = this.recognitionCooldown.get(studentId);
                    if (now - lastRecording < this.cooldownMs) return;
                }
                
                try {
                    const response = await fetch('/api/record-attendance/', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({
                            student_id: studentId,
                            type: this.attendanceType
                        })
                    });
                    
                    const data = await response.json();
                    
                    if (data.success) {
                        this.recognitionCooldown.set(studentId, now);
                        this.showNotification(data.message, 'success');
                    }
                } catch (error) {
                    console.error('Error recording attendance:', error);
                }
            }

            updateFPS() {
                this.frameCount++;
                const now = Date.now();
                const elapsed = now - this.lastFpsUpdate;
                
                if (elapsed >= 1000) {
                    this.fps = Math.round(this.frameCount * 1000 / elapsed);
                    this.frameCount = 0;
                    this.lastFpsUpdate = now;
                    
                    const fpsElement = document.getElementById('fps-counter');
                    if (fpsElement) {
                        fpsElement.textContent = `${this.fps} FPS`;
                        fpsElement.className = this.fps >= 10 ? 'text-green-500 font-bold' : 
                                               this.fps >= 5 ? 'text-yellow-500 font-bold' : 
                                               'text-red-500 font-bold';
                    }
                }
            }

            showNotification(message, type = 'info') {
                const toast = document.createElement('div');
                toast.className = `fixed top-5 right-5 px-6 py-4 rounded-lg shadow-lg text-white ${
                    type === 'success' ? 'bg-green-500' : 
                    type === 'error' ? 'bg-red-500' : 'bg-blue-500'
                } animate-fade-in z-50`;
                toast.textContent = message;
                
                document.body.appendChild(toast);
                setTimeout(() => toast.remove(), 3000);
            }
        }

        // Initialize when DOM loads
        let faceRecognition = null;
        
        window.addEventListener('DOMContentLoaded', async () => {
            faceRecognition = new UltraFastFaceRecognition(ATTENDANCE_TYPE);
            await faceRecognition.initialize();
            
            const webcamVideo = document.getElementById('webcam');
            
            // Hook into video playing event
            webcamVideo.addEventListener('playing', () => {
                console.log('üìπ Camera playing, starting face recognition...');
                setTimeout(() => {
                    if (faceRecognition && webcamVideo.readyState === 4) {
                        faceRecognition.startRecognition();
                    }
                }, 1000);
            });
            
            // Stop recognition when video pauses/stops
            webcamVideo.addEventListener('pause', () => {
                if (faceRecognition) {
                    faceRecognition.stopRecognition();
                }
            });
        });
        
        // Cleanup
        window.addEventListener('beforeunload', () => {
            if (faceRecognition) {
                faceRecognition.stopRecognition();
            }
        });
    })();
    </script>
</body>
</html>
