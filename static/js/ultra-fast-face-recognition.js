/**
 * Ultra-Fast Face Recognition System
 * Optimized for 10+ FPS with GPU acceleration
 * Compares detected faces against hundreds of student embeddings
 */

class UltraFastFaceRecognition {
    constructor(attendanceType = 'time_in') {
        this.attendanceType = attendanceType; // 'time_in' or 'time_out'
        this.video = null;
        this.canvas = null;
        this.ctx = null;
        this.model = null;
        this.isRunning = false;
        this.detectedFaces = new Map(); // Store recent detections to avoid duplicates
        this.processingFrame = false;
        this.frameCount = 0;
        this.fps = 0;
        this.lastFpsUpdate = Date.now();
        this.recognitionCooldown = new Map(); // Cooldown per student to avoid spam
        this.cooldownMs = 5000; // 5 seconds between same student recognition
        this.currentDetections = []; // Store current frame detections to continuously draw
    }

    async initialize() {
        console.log('ðŸš€ Initializing Ultra-Fast Face Recognition...');
        
        // Get video and canvas elements
        this.video = document.getElementById('webcam');
        this.canvas = document.getElementById('overlay-canvas');
        this.ctx = this.canvas.getContext('2d');
        
        // Enable WebGL for GPU acceleration
        const gl = this.canvas.getContext('webgl') || this.canvas.getContext('experimental-webgl');
        if (gl) {
            console.log('âœ… WebGL enabled - GPU acceleration active');
        }
        
        // Start webcam
        await this.startWebcam();
        
        // Load BlazeFace model (ultra-fast face detection)
        console.log('ðŸ“¥ Loading BlazeFace model...');
        this.model = await blazeface.load();
        console.log('âœ… BlazeFace model loaded');
        
        // Start recognition loop
        this.isRunning = true;
        this.recognitionLoop();
        
        console.log('âœ… Face Recognition System Ready!');
    }

    async startWebcam() {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({
                video: {
                    width: { ideal: 1280 },
                    height: { ideal: 720 },
                    frameRate: { ideal: 30 }
                }
            });
            
            this.video.srcObject = stream;
            
            return new Promise((resolve) => {
                this.video.onloadedmetadata = () => {
                    this.video.play();
                    
                    // Set canvas size to match video
                    this.canvas.width = this.video.videoWidth;
                    this.canvas.height = this.video.videoHeight;
                    
                    resolve();
                };
            });
        } catch (error) {
            console.error('âŒ Error accessing webcam:', error);
            throw error;
        }
    }

    async recognitionLoop() {
        if (!this.isRunning) return;
        
        // Clear canvas and redraw detections every frame
        this.ctx.clearRect(0, 0, this.canvas.width, this.canvas.height);
        this.redrawDetections();
        
        // Process frame if not already processing
        if (!this.processingFrame) {
            this.processingFrame = true;
            this.processFrame().then(() => {
                this.processingFrame = false;
            }).catch(error => {
                console.error('Error in processFrame:', error);
                this.processingFrame = false;
            });
        }
        
        // Continue loop
        requestAnimationFrame(() => this.recognitionLoop());
    }

    async processFrame() {
        try {
            // Detect faces using BlazeFace
            const predictions = await this.model.estimateFaces(this.video, false);
            
            if (predictions.length === 0) {
                // No faces detected - clear current detections
                this.currentDetections = [];
                return;
            }
            
            // Extract face embeddings for all detected faces
            const faceEmbeddings = [];
            const faceBoundingBoxes = [];
            
            for (const prediction of predictions) {
                const start = prediction.topLeft;
                const end = prediction.bottomRight;
                const size = [end[0] - start[0], end[1] - start[1]];
                
                // Extract face region
                const faceEmbedding = await this.extractFaceEmbedding(start, size);
                faceEmbeddings.push(faceEmbedding);
                faceBoundingBoxes.push({ start, end, size });
            }
            
            // Send embeddings to backend for recognition (batch processing)
            const results = await this.recognizeFaces(faceEmbeddings);
            
            // Store detections for continuous drawing
            this.currentDetections = [];
            for (let i = 0; i < results.length; i++) {
                const result = results[i];
                const box = faceBoundingBoxes[i];
                
                this.currentDetections.push({
                    box: box,
                    result: result,
                    isMatched: result.matched
                });
                
                if (result.matched) {
                    // Auto-record attendance if not in cooldown
                    this.autoRecordAttendance(result);
                }
            }
            
            // Update FPS counter
            this.updateFPS();
            
        } catch (error) {
            console.error('Error in processFrame:', error);
        }
    }
    
    redrawDetections() {
        // Continuously draw stored detections every frame
        for (const detection of this.currentDetections) {
            this.drawBoundingBox(detection.box, detection.result, detection.isMatched);
        }
    }

    async extractFaceEmbedding(start, size) {
        /**
         * Extract face embedding from video frame
         * This creates a simplified embedding based on face region
         * In production, use FaceNet or similar for real embeddings
         */
        const [x, y] = start;
        const [width, height] = size;
        
        // Create temporary canvas for face extraction
        const faceCanvas = document.createElement('canvas');
        faceCanvas.width = 128;
        faceCanvas.height = 128;
        const faceCtx = faceCanvas.getContext('2d');
        
        // Draw face region (resized to 128x128)
        faceCtx.drawImage(
            this.video,
            x, y, width, height,
            0, 0, 128, 128
        );
        
        // Get image data
        const imageData = faceCtx.getImageData(0, 0, 128, 128);
        const data = imageData.data;
        
        // Create simplified embedding (128 dimensions)
        // This is a placeholder - use FaceNet for real embeddings
        const embedding = new Array(128);
        for (let i = 0; i < 128; i++) {
            const idx = i * 4 * 128; // Sample pixels
            embedding[i] = (data[idx] + data[idx + 1] + data[idx + 2]) / (3 * 255);
        }
        
        return embedding;
    }

    async recognizeFaces(faceEmbeddings) {
        /**
         * Send face embeddings to backend for recognition
         * Backend compares against all student embeddings in parallel
         */
        try {
            const response = await fetch('/api/recognize-faces/', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    face_embeddings: faceEmbeddings
                })
            });
            
            const data = await response.json();
            
            if (data.success) {
                return data.results;
            } else {
                console.error('Recognition failed:', data.error);
                return faceEmbeddings.map(() => ({ matched: false }));
            }
        } catch (error) {
            console.error('Error in recognizeFaces:', error);
            return faceEmbeddings.map(() => ({ matched: false }));
        }
    }

    drawBoundingBox(box, result, isMatched) {
        const { start, end } = box;
        const [x1, y1] = start;
        const [x2, y2] = end;
        
        // Set colors
        const color = isMatched ? '#00FF00' : '#FF0000'; // Green or Red
        const bgColor = isMatched ? 'rgba(0, 255, 0, 0.2)' : 'rgba(255, 0, 0, 0.2)';
        
        console.log(`ðŸŽ¨ Drawing box at [${x1}, ${y1}] to [${x2}, ${y2}] - Color: ${color}`);
        
        // Draw rectangle
        this.ctx.strokeStyle = color;
        this.ctx.lineWidth = 4;
        this.ctx.strokeRect(x1, y1, x2 - x1, y2 - y1);
        
        // Draw background for text
        this.ctx.fillStyle = bgColor;
        this.ctx.fillRect(x1, y1 - 30, x2 - x1, 30);
        
        // Draw text
        this.ctx.fillStyle = color;
        this.ctx.font = 'bold 16px Arial';
        
        if (isMatched) {
            const text = `LRN: ${result.lrn}`;
            this.ctx.fillText(text, x1 + 5, y1 - 10);
        } else {
            this.ctx.fillText('UNAUTHORIZED', x1 + 5, y1 - 10);
        }
        
        // Draw confidence if matched
        if (isMatched && result.confidence) {
            this.ctx.font = '12px Arial';
            this.ctx.fillText(`${(result.confidence * 100).toFixed(1)}%`, x2 - 50, y1 - 10);
        }
    }

    async autoRecordAttendance(result) {
        /**
         * Automatically record attendance when student is recognized
         * Uses cooldown to prevent duplicate recordings
         */
        const studentId = result.student_id;
        const now = Date.now();
        
        // Check cooldown
        if (this.recognitionCooldown.has(studentId)) {
            const lastRecording = this.recognitionCooldown.get(studentId);
            if (now - lastRecording < this.cooldownMs) {
                return; // Still in cooldown
            }
        }
        
        // Record attendance
        try {
            const response = await fetch('/api/record-attendance/', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    student_id: studentId,
                    type: this.attendanceType
                })
            });
            
            const data = await response.json();
            
            if (data.success) {
                // Set cooldown
                this.recognitionCooldown.set(studentId, now);
                
                // Show success notification
                this.showNotification(data.message, 'success');
                
                // Play success sound
                this.playSound('success');
            } else {
                console.log('Attendance recording failed:', data.message);
            }
        } catch (error) {
            console.error('Error recording attendance:', error);
        }
    }

    updateFPS() {
        this.frameCount++;
        const now = Date.now();
        const elapsed = now - this.lastFpsUpdate;
        
        if (elapsed >= 1000) {
            this.fps = Math.round(this.frameCount * 1000 / elapsed);
            this.frameCount = 0;
            this.lastFpsUpdate = now;
            
            // Update FPS display
            const fpsElement = document.getElementById('fps-counter');
            if (fpsElement) {
                fpsElement.textContent = `${this.fps} FPS`;
                
                // Color code based on performance
                if (this.fps >= 10) {
                    fpsElement.className = 'text-green-500 font-bold';
                } else if (this.fps >= 5) {
                    fpsElement.className = 'text-yellow-500 font-bold';
                } else {
                    fpsElement.className = 'text-red-500 font-bold';
                }
            }
        }
    }

    showNotification(message, type = 'info') {
        // Create toast notification
        const toast = document.createElement('div');
        toast.className = `fixed top-5 right-5 px-6 py-4 rounded-lg shadow-lg text-white ${
            type === 'success' ? 'bg-green-500' : 
            type === 'error' ? 'bg-red-500' : 'bg-blue-500'
        } animate-fade-in z-50`;
        toast.textContent = message;
        
        document.body.appendChild(toast);
        
        // Remove after 3 seconds
        setTimeout(() => {
            toast.remove();
        }, 3000);
    }

    playSound(type) {
        // Play sound effect
        const audio = new Audio(type === 'success' ? '/static/sounds/success.mp3' : '/static/sounds/error.mp3');
        audio.volume = 0.3;
        audio.play().catch(() => {
            // Ignore if sound fails
        });
    }

    stop() {
        this.isRunning = false;
        if (this.video && this.video.srcObject) {
            const tracks = this.video.srcObject.getTracks();
            tracks.forEach(track => track.stop());
        }
    }
}

// Global instance
let faceRecognition = null;

// Initialize when page loads
document.addEventListener('DOMContentLoaded', () => {
    const attendanceType = document.body.dataset.attendanceType || 'time_in';
    faceRecognition = new UltraFastFaceRecognition(attendanceType);
    faceRecognition.initialize().catch(error => {
        console.error('Failed to initialize face recognition:', error);
        alert('Failed to initialize face recognition. Please check camera permissions.');
    });
});

// Cleanup on page unload
window.addEventListener('beforeunload', () => {
    if (faceRecognition) {
        faceRecognition.stop();
    }
});
